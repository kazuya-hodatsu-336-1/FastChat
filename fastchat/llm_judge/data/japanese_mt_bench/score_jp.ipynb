{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3592ec6-d74b-4b84-a951-340ffc94c80c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: ['Qwen3-4B_t0.2' 'HCSD_MPO_v2_Qwen3-4Bt0.2' 'Qwen3-4B-HCSD_MPO_SFT3_t02'\n",
      " 'Qwen3-4B-HCSD_MPO_SFT1_16k_t02' 'Qwen3-4B-HCSD_MPO_SFT1_4k_t02_1.2'\n",
      " 'HCSD_MPO_v2_Qwen3-8B' 'HCSD_MPO_v2_Qwen3-8B_16k' 'Qwen3-8B_16k'\n",
      " 'HCSD_MPO_v2_Qwen3-8B_t00' 'HCSD_MPO_v2_Qwen3-8B_0.2_0310'\n",
      " 'HCSD_MPO_v2_Qwen3-8B_0.2_0320' 'HCSD_MPO_v2_Qwen3-8B_0.6_0304'\n",
      " 'HCSD_MPO_v2_Qwen3-8B_0.6_0315' 'Qwen3-8B_0.2_0348' 'Qwen3-8B_0.2_0357'\n",
      " 'Qwen3-8B_0.6_0343' 'Qwen3-8B_0.6_0353']\n",
      "category                           Coding  Extraction  Humanities  Math  Reasoning  Roleplay  STEM  Writing\n",
      "model                                                                                                      \n",
      "HCSD_MPO_v2_Qwen3-4Bt0.2             8.50        8.50        8.65  9.00       6.45      8.15  8.35     7.85\n",
      "HCSD_MPO_v2_Qwen3-8B                 8.10        7.85        8.70  8.90       5.70      8.85  8.65     8.65\n",
      "HCSD_MPO_v2_Qwen3-8B_0.2_0310        8.75        8.45        8.85  9.25       6.65      8.75  9.00     8.30\n",
      "HCSD_MPO_v2_Qwen3-8B_0.2_0320        8.90        8.10        9.00  9.15       7.00      8.85  8.85     8.55\n",
      "HCSD_MPO_v2_Qwen3-8B_0.6_0304        8.75        8.65        8.65  9.10       6.50      8.95  8.80     8.50\n",
      "HCSD_MPO_v2_Qwen3-8B_0.6_0315        8.60        8.30        8.80  8.65       6.00      8.85  9.05     8.75\n",
      "HCSD_MPO_v2_Qwen3-8B_16k             8.75        8.80        8.95  9.25       6.65      8.90  8.95     8.40\n",
      "HCSD_MPO_v2_Qwen3-8B_t00             7.35        8.00        9.05  8.40       4.95      6.75  8.05     7.95\n",
      "Qwen3-4B-HCSD_MPO_SFT1_16k_t02       8.55        8.25        8.55  9.25       6.00      7.75  9.00     7.95\n",
      "Qwen3-4B-HCSD_MPO_SFT1_4k_t02_1.2    7.20        7.40        8.80  8.75       5.30      8.30  8.80     8.15\n",
      "Qwen3-4B-HCSD_MPO_SFT3_t02           7.60        7.80        8.60  8.55       5.55      8.60  8.80     8.35\n",
      "Qwen3-4B_t0.2                        8.10        8.70        8.75  8.65       6.00      8.25  8.40     8.50\n",
      "Qwen3-8B_0.2_0348                    9.10        8.20        8.85  8.45       6.50      8.90  8.95     9.00\n",
      "Qwen3-8B_0.2_0357                    8.75        8.20        8.95  8.65       6.20      8.80  8.70     8.70\n",
      "Qwen3-8B_0.6_0343                    8.75        8.25        8.85  8.55       6.05      8.60  8.70     8.75\n",
      "Qwen3-8B_0.6_0353                    8.75        8.00        8.75  8.55       5.55      8.60  9.00     8.50\n",
      "Qwen3-8B_16k                         9.05        8.20        8.95  8.95       6.35      8.95  8.70     8.85\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "CATEGORIES = [\"Coding\", \"Extraction\", \"Humanities\", \"Math\", \"Reasoning\", \"Roleplay\", \"STEM\", \"Writing\"]\n",
    "\n",
    "def get_model_df():\n",
    "    q2result = []\n",
    "    with open(\"./model_judgment/gpt-4o_single.jsonl\", \"r\") as fin:\n",
    "        for line in fin:\n",
    "            obj = json.loads(line)\n",
    "            obj[\"category\"] = CATEGORIES[(int(obj[\"question_id\"])-1)//10]\n",
    "            q2result.append(obj)\n",
    "    return pd.DataFrame(q2result)\n",
    "\n",
    "df = get_model_df()\n",
    "all_models = df[\"model\"].unique()\n",
    "print(\"Available models:\", all_models)\n",
    "##\n",
    "scores_all = []\n",
    "for model in all_models:\n",
    "    for cat in CATEGORIES:\n",
    "        res = df[(df[\"category\"]==cat) & (df[\"model\"]==model) & (df[\"score\"] >= 0)]\n",
    "        score = res[\"score\"].mean()\n",
    "        scores_all.append({\"model\": model, \"category\": cat, \"score\": score})\n",
    "\n",
    "target_models = all_models\n",
    "scores_target = [score for score in scores_all if score[\"model\"] in target_models]\n",
    "\n",
    "# スコアを表示\n",
    "# for score in scores_target:\n",
    "#     print(f\"Model: {score['model']}, Category: {score['category']}, Score: {score['score']:.2f}\")\n",
    "import pandas as pd\n",
    "\n",
    "# スコアをDataFrameに変換\n",
    "df_scores = pd.DataFrame(scores_target)\n",
    "\n",
    "# Pivotして表形式に変換\n",
    "pivot_df = df_scores.pivot(index=\"model\", columns=\"category\", values=\"score\")\n",
    "pd.set_option(\"display.width\", 200)            # 表示幅を広く\n",
    "pd.set_option(\"display.max_columns\", None)     # カラム数の制限解除\n",
    "\n",
    "# 表示（必要ならNaNを0や\"-\"などに変換可能）\n",
    "print(pivot_df.round(2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
